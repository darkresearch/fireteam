---
title: "Agents"
description: "Understanding the specialized AI agents that power Fireteam's autonomous development"
---

## Agent Architecture

Fireteam employs three specialized AI agents, each with a distinct role in the development cycle. All agents are powered by **Claude AI** through the Claude CLI, with specialized prompts that guide their behavior.

```
┌─────────────────────────────────────────────────┐
│              BaseAgent (Abstract)               │
│  - Claude CLI invocation                        │
│  - Timeout management                           │
│  - Retry logic with exponential backoff         │
│  - Error handling                               │
└─────────────────────────────────────────────────┘
                       │
        ┌──────────────┼──────────────┐
        │              │              │
        ▼              ▼              ▼
  ┌──────────┐  ┌──────────┐  ┌──────────┐
  │ Planner  │  │ Executor │  │ Reviewer │
  │  Agent   │  │  Agent   │  │  Agent   │
  └──────────┘  └──────────┘  └──────────┘
```

## BaseAgent Class

All agents inherit from **BaseAgent** (`agents/base.py`), which provides common functionality:

### Core Features

**Claude CLI Integration**:
```python
claude --print --dangerously-skip-permissions "<prompt>"
```

**Configurable Timeouts**:
- Planner: 10 minutes (600 seconds)
- Executor: 30 minutes (1800 seconds)
- Reviewer: 10 minutes (600 seconds)

**Retry Logic**:
- Maximum retries: 3 attempts
- Retry delay: 5 seconds
- Exponential backoff on failures
- Detailed error logging

**Error Handling**:
- Timeout exceptions
- Command execution errors
- Network failures
- Graceful degradation

### BaseAgent Methods

```python
class BaseAgent:
    def __init__(self, agent_type: str, logger: Logger):
        self.agent_type = agent_type
        self.timeout = AGENT_TIMEOUTS[agent_type]
        self.max_retries = MAX_RETRIES

    def _build_command(self, prompt: str, project_dir: str) -> list:
        """Build Claude CLI command with prompt."""

    def _execute_command(self, cmd: list, project_dir: str) -> dict:
        """Execute command with retry logic."""

    def execute(self, **kwargs) -> dict:
        """Must be implemented by subclasses."""
```

## Planner Agent

The **Planner Agent** (`agents/planner.py`) is the strategic thinker that creates and updates project plans.

### Role & Responsibilities

<Card title="Strategic Planning" icon="map">
  Creates comprehensive, actionable project plans that break down goals into concrete tasks
</Card>

**Key Responsibilities**:
- Analyze the project goal
- Break down work into actionable tasks
- Organize tasks in logical order
- Identify key milestones
- Consider edge cases and testing requirements
- Update plans based on execution feedback
- Adapt to blockers and changes

### Input & Output

**Cycle 0 (Initial Planning)**:
- **Input**: Project goal only
- **Output**: Comprehensive initial plan

**Cycle 1+ (Plan Updates)**:
- **Input**: Goal, previous plan, execution result, review feedback
- **Output**: Updated plan with progress and adjusted priorities

### Prompt Strategy

#### Initial Plan Prompt (Cycle 0)

The Planner receives a focused prompt to create the first plan:

```
You are a Planner Agent in an autonomous multi-agent system.

PROJECT GOAL:
{goal}

YOUR TASK:
Create a comprehensive, actionable project plan to achieve this goal.

Your plan should:
1. Break down the goal into clear, concrete tasks
2. Organize tasks in logical order
3. Identify key milestones
4. Consider edge cases and testing requirements
5. Aim for production-ready quality

OUTPUT FORMAT:
- Overview/Summary
- Task breakdown with priorities
- Key milestones
- Testing strategy
- Success criteria
```

#### Update Plan Prompt (Cycle 1+)

For subsequent cycles, the Planner gets full context:

```
PROJECT GOAL: {goal}
CYCLE NUMBER: {cycle_number}
PREVIOUS PLAN: {previous_plan}
LAST EXECUTION RESULT: {execution_result}
LAST REVIEW: {review_feedback}

YOUR TASK:
Update the project plan based on progress and feedback.

Consider:
1. What has been completed successfully?
2. What issues or blockers were encountered?
3. What tasks remain?
4. What adjustments are needed?
5. Are we ready for final validation?
```

### Timeout Rationale

**10 minutes** - Why?

- Planning is primarily analytical work (reading, thinking, organizing)
- No code execution or testing required
- Claude can analyze codebases quickly
- Test data shows planning rarely needs more time
- Longer timeouts would slow cycle throughput

<Tip>
If your projects require complex planning, you can increase the planner timeout in `config.py`:

```python
AGENT_TIMEOUTS = {
    "planner": 900,  # 15 minutes
}
```
</Tip>

### Example Plan Output

```markdown
# Project Plan - Cycle 2

## Progress Summary
- ✅ Core API integration complete
- ✅ Basic CLI interface working
- ⚠️ Error handling needs improvement
- ❌ Tests incomplete

## Updated Task List

### High Priority
1. [IN PROGRESS] Add comprehensive error handling
   - Retry logic for API failures
   - Network timeout handling
   - Invalid response validation

2. [TODO] Complete test suite
   - Unit tests for API client
   - Integration tests for CLI
   - Edge case coverage

### Medium Priority
3. [TODO] Documentation polish
   - Usage examples
   - API documentation
   - Installation instructions

## Next Steps
Focus on error handling in this cycle. The Executor should prioritize
tasks 1 and 2 to move toward 95% completion threshold.
```

## Executor Agent

The **Executor Agent** (`agents/executor.py`) is the hands-on builder that transforms plans into working code.

### Role & Responsibilities

<Card title="Implementation Specialist" icon="code">
  Executes planned tasks by writing production-ready, tested code
</Card>

**Key Responsibilities**:
- Implement tasks from the current plan
- Write clean, production-quality code
- Create tests for implementations
- Handle errors gracefully
- Document code and usage
- Leave codebase in functional state

### Input & Output

**Input**:
- Project goal
- Current plan from Planner
- Cycle number
- Project directory path

**Output**:
- Summary of work completed
- Files created/modified
- Issues encountered
- Remaining work

### Prompt Strategy

The Executor receives a task-focused prompt:

```
You are an Executor Agent in an autonomous multi-agent system.

PROJECT GOAL: {goal}
CYCLE NUMBER: {cycle_number}
CURRENT PLAN: {plan}

YOUR TASK:
Execute the tasks outlined in the plan. You should:

1. Work through tasks systematically
2. Create/modify files as needed
3. Write clean, production-ready code
4. Test your implementations
5. Handle errors gracefully
6. Document your work

IMPORTANT:
- Focus on the NEXT actionable tasks from the plan
- Write actual, working code (not pseudocode)
- Test thoroughly before considering tasks complete
- If you encounter blockers, document them clearly
- Leave the codebase in a functional state

OUTPUT FORMAT:
Provide a summary of:
- What you accomplished
- What files you created/modified
- Any issues encountered
- What still needs to be done

Work efficiently and aim for quality. Do not leave placeholders or
incomplete implementations.
```

### Timeout Rationale

**30 minutes** - Why?

- Implementation is the most time-intensive phase
- Includes writing code, running tests, debugging
- May involve installing dependencies (`pip install`, `npm install`)
- Large projects may need significant file operations
- Test data confirms executor needs the most time

<Info>
The executor has **3x the timeout** of other agents because implementation includes:
- Writing multiple files
- Running test suites
- Installing and configuring dependencies
- Debugging failures
- Building/compiling code
</Info>

### Example Execution Output

```
# Execution Summary - Cycle 2

## Accomplished
✅ Added comprehensive error handling to API client
  - Implemented retry logic with exponential backoff (3 attempts)
  - Added network timeout handling (10s default)
  - Validate API responses before parsing

✅ Expanded test suite
  - Added 12 new unit tests for API client (tests/test_api.py:25-150)
  - Added integration tests for CLI (tests/test_cli.py)
  - All 18 tests passing

✅ Improved documentation
  - Updated README with installation steps
  - Added usage examples
  - Documented error codes

## Files Modified
- src/api_client.py (75 lines changed)
- src/cli.py (23 lines changed)
- tests/test_api.py (120 lines added)
- tests/test_cli.py (new file, 85 lines)
- README.md (45 lines changed)

## Issues Encountered
- None

## Remaining Work
- Performance optimization (low priority)
- Additional edge case tests (nice-to-have)

## Status
Project is feature-complete and production-ready. Ready for review.
```

## Reviewer Agent

The **Reviewer Agent** (`agents/reviewer.py`) is the quality control expert that validates progress and estimates completion.

### Role & Responsibilities

<Card title="Quality Assurance" icon="magnifying-glass">
  Critically evaluates the codebase, runs tests, and estimates completion percentage
</Card>

**Key Responsibilities**:
- Examine the entire codebase
- Run tests and verify functionality
- Compare implementation against goal
- Identify gaps, bugs, or incomplete features
- Calculate honest completion percentage (0-100%)
- Provide actionable feedback

### Input & Output

**Input**:
- Project goal
- Current plan
- Execution result summary
- Cycle number
- Validation mode flag (true when completion ≥95%)

**Output**:
- Completion percentage (0-100%)
- Review summary
- What's working well
- What's incomplete or broken
- Next steps

### Prompt Strategy

#### Standard Review Prompt

```
You are a Reviewer Agent in an autonomous multi-agent system.

PROJECT GOAL: {goal}
CYCLE NUMBER: {cycle_number}
CURRENT PLAN: {plan}
LATEST EXECUTION RESULT: {execution_result}

YOUR TASK:
Review the project's current state and assess progress.

You should:
1. Examine the codebase thoroughly
2. Check what has been implemented vs. planned
3. Test functionality where possible
4. Identify gaps, issues, or incomplete work
5. Assess production-readiness
6. Provide an honest completion estimate

COMPLETION CRITERIA:
- 0%: Nothing started
- 25%: Basic structure in place
- 50%: Core functionality implemented
- 75%: Most features working, needs polish
- 90%: Feature complete, needs testing
- 95%: Production-ready with comprehensive testing
- 100%: Perfect, nothing more needed

OUTPUT FORMAT:
Your response MUST include a completion percentage in this format:
COMPLETION: XX%

Then provide:
- Summary of current state
- What's working well
- What's incomplete or broken
- What needs to be done next
- Whether ready for production

Be honest and critical. Don't inflate percentages.
```

#### Validation Mode (≥95% Completion)

When the project reaches ≥95%, the Reviewer enters **critical validation mode**:

```
VALIDATION MODE:
This is a validation check. The system believes the project is >95%
complete.

Be CRITICAL and thorough. Check for:
- Edge cases that might not be handled
- Missing error handling
- Incomplete features
- Testing gaps
- Production-readiness issues

Only confirm high completion if truly production-ready.
```

This prevents false positives and ensures genuine quality.

### Completion Percentage Extraction

The Reviewer's output is parsed to extract the completion percentage:

```python
# Primary pattern: "COMPLETION: XX%"
match = re.search(r'COMPLETION:\s*(\d+)%', output, re.IGNORECASE)

# Fallback: Any percentage in output
if not match:
    match = re.search(r'(\d+)%', output)

# Default: 0% if parsing fails
completion = int(match.group(1)) if match else 0
```

### Timeout Rationale

**10 minutes** - Why?

- Review is analytical (code reading, test running)
- No code writing or large file operations
- Test suites typically run in seconds to minutes
- Claude can scan codebases efficiently
- Similar to Planner in complexity

### Example Review Output

```
COMPLETION: 98%

## Summary of Current State

The Bitcoin CLI project is **production-ready** with comprehensive
functionality, testing, and documentation.

## What's Working Well

✅ **Core Functionality**
- CoinGecko API integration working flawlessly
- Clean CLI interface with argparse
- Formatted output (price, 24h change, market cap)

✅ **Error Handling**
- Retry logic with exponential backoff
- Network timeout handling (10s)
- Invalid response validation
- Graceful degradation on API failures

✅ **Testing**
- 18 unit tests, all passing
- Integration tests cover main workflows
- Edge cases tested (network failures, invalid responses)

✅**Documentation**
- Clear README with installation and usage
- Code comments explain complex logic
- Error messages are user-friendly

## What's Incomplete or Broken

⚠️ **Minor Polish Items** (not blocking)
- Could add support for multiple cryptocurrencies (scope creep)
- Performance could be optimized (not needed for CLI)

## Next Steps

Project is ready for production deployment. No critical work remains.
The minor polish items are nice-to-haves that exceed the original goal.

## Production Ready?

**YES** - This project meets the goal, has comprehensive testing, handles
errors gracefully, and is documented. Recommend validation completion.
```

## Agent Communication

Agents **do not communicate directly**. The Orchestrator manages all data flow:

```
Cycle N:
  1. Orchestrator calls Planner
     - Passes: goal, previous_plan, last_review
     - Receives: new_plan

  2. Orchestrator calls Executor
     - Passes: goal, new_plan
     - Receives: execution_result

  3. Orchestrator calls Reviewer
     - Passes: goal, new_plan, execution_result
     - Receives: review, completion_percentage

  4. Orchestrator saves all outputs to state.json

  5. Orchestrator commits changes to Git

  6. Cycle repeats
```

This architecture ensures:
- **Clean separation of concerns**: Each agent has a single, well-defined role
- **Stateless agents**: No persistent memory between invocations
- **Reproducible behavior**: Same inputs → same outputs
- **Easy debugging**: All communication logged and tracked

## Timeout Configuration

All agent timeouts are configurable in `config.py`:

```python
# agents/base.py
AGENT_TIMEOUTS = {
    "planner": 600,      # 10 minutes
    "reviewer": 600,     # 10 minutes
    "executor": 1800     # 30 minutes
}
```

### When to Adjust Timeouts

**Increase Planner timeout** if:
- Working with very large, complex codebases
- Planning requires extensive analysis
- Projects have many dependencies to review

**Increase Executor timeout** if:
- Projects require long build/compile times
- Large test suites take >10 minutes to run
- Dependency installation is slow (Node.js projects)

**Increase Reviewer timeout** if:
- Test suites take >5 minutes to run
- Projects have extensive codebases to scan
- Complex integration tests needed

<Warning>
Increasing timeouts will slow down cycle throughput. Only adjust if you're seeing frequent timeouts in logs.
</Warning>

## Performance Insights

Based on real test data across 11 projects:

### Planner Performance
- **Average time**: 2-5 minutes per cycle
- **Timeout rate**: &lt;1% (rarely times out)
- **Success rate**: 99%+

### Executor Performance
- **Average time**: 10-20 minutes per cycle
- **Timeout rate**: ~5% (mainly on first cycle of complex projects)
- **Success rate**: 95%+
- **Bottleneck**: Dependency installation (Node.js, large Python packages)

### Reviewer Performance
- **Average time**: 3-7 minutes per cycle
- **Timeout rate**: &lt;2%
- **Success rate**: 98%+
- **Accuracy**: Completion estimates within ±5% of reality

## Best Practices

### For Better Planning
- Provide detailed, specific goals
- Include desired tech stack in goal description
- Mention testing and documentation requirements

### For Better Execution
- Plans should have clear, actionable tasks
- Avoid vague instructions like "improve code quality"
- Specify exact features and acceptance criteria

### For Better Reviews
- Let Reviewer be critical (it's designed to be)
- Don't second-guess low completion percentages
- Trust the triple-validation system

## Next Steps

<CardGroup cols={2}>
  <Card title="Understand Cycles" icon="rotate" href="/core-concepts/cycles">
    Learn how agents work together in cycles
  </Card>

  <Card title="Configure Timeouts" icon="clock" href="/configuration/timeouts">
    Optimize timeouts for your projects
  </Card>

  <Card title="View Architecture" icon="diagram-project" href="/core-concepts/architecture">
    See the big picture
  </Card>

  <Card title="State Management" icon="database" href="/advanced/state-management">
    How state flows between agents
  </Card>
</CardGroup>
