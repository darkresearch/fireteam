---
title: Quality Hooks
description: Enforce quality with SDK hooks
---

# Quality Hooks

Fireteam includes SDK hooks that enforce quality during execution. These hooks run tests after edits and can block user interaction for fully autonomous operation.

## Built-in Hook Sets

### QUALITY_HOOKS

The default hooks for quality enforcement:

- **Run tests after edits**: Automatically runs `pytest`, `npm test`, `cargo test`, etc. after Write/Edit operations
- **Block user questions**: Prevents Claude from asking questions (fully autonomous)

```python
from fireteam import execute

# QUALITY_HOOKS enabled by default when run_tests=True
result = await execute(
    project_dir="/path/to/project",
    goal="Add feature",
    run_tests=True,  # Default
)
```

### AUTONOMOUS_HOOKS

For fully autonomous operation without any user interaction:

- Blocks `AskUserQuestion` tool

```python
from fireteam.hooks import AUTONOMOUS_HOOKS
```

### DEBUG_HOOKS

For debugging and logging:

- Logs all tool usage

```python
from fireteam.hooks import DEBUG_HOOKS
```

## Test Detection

Fireteam automatically detects your test framework:

| Framework | Detection | Command |
|-----------|-----------|---------|
| pytest | `pytest.ini`, `pyproject.toml`, `setup.py`, `tests/` | `pytest -x --tb=short` |
| npm | `package.json` | `npm test` |
| cargo | `Cargo.toml` | `cargo test` |
| go | `go.mod` | `go test ./...` |
| make | `Makefile` with `test:` target | `make test` |

## How Hooks Work

### PreToolUse Hooks

Run before a tool is used. Can approve, deny, or modify the tool call.

```python
async def block_user_questions(event, context, config):
    """Block AskUserQuestion for autonomous operation."""
    if event.get("hook_event_name") != "PreToolUse":
        return {}
    if event.get("tool_name") != "AskUserQuestion":
        return {}

    return {
        "hookSpecificOutput": {
            "permissionDecision": "deny",
            "permissionDecisionReason": "Autonomous mode - no user interaction",
        }
    }
```

### PostToolUse Hooks

Run after a tool completes. Can provide feedback to Claude.

```python
async def run_tests_after_edit(event, context, config):
    """Run tests after Write/Edit operations."""
    if event.get("hook_event_name") != "PostToolUse":
        return {}
    if event.get("tool_name") not in ["Edit", "Write"]:
        return {}

    # Run tests and return results
    success, output = run_tests_sync(cwd, test_command)

    if success:
        return {}  # No feedback needed

    return {
        "hookSpecificOutput": {
            "additionalContext": f"Tests failed:\n{output}",
        }
    }
```

## Disabling Hooks

To disable test running and hooks:

```python
result = await execute(
    project_dir="/path/to/project",
    goal="Add experimental feature",
    run_tests=False,  # Disables QUALITY_HOOKS
)
```

## Custom Hooks

Create custom hooks for your use case:

```python
from fireteam.hooks import create_test_hooks

# Get the default test hooks configuration
hooks = create_test_hooks()

# Modify or extend as needed
print(hooks)
# {
#     "PreToolUse": [...],
#     "PostToolUse": [...],
# }
```

## Hook Events

| Event | When | Purpose |
|-------|------|---------|
| PreToolUse | Before tool execution | Approve/deny/modify |
| PostToolUse | After tool execution | Provide feedback |

## Test Output

When tests fail, the hook provides feedback to Claude:

```
Tests failed after editing src/auth.py:
FAILED tests/test_auth.py::test_login - AssertionError
1 failed, 5 passed
```

Claude receives this feedback and can fix the issue before continuing.
